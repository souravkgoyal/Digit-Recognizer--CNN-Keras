{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem Statement"},{"metadata":{},"cell_type":"markdown","source":"In this competition, goal is to correctly identify digits from a dataset of tens of thousands of handwritten images."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":117,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importng Required Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":118,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Prepration"},{"metadata":{},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(r'/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv(r'/kaggle/input/digit-recognizer/test.csv')","execution_count":119,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['label']\nX_train=train.drop('label',axis=1)","execution_count":120,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nplt.figure(figsize=(7,5))\nsns.countplot(y_train)","execution_count":121,"outputs":[{"output_type":"execute_result","execution_count":121,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f426db0ee50>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 504x360 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Check for Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.isnull().any().describe()","execution_count":122,"outputs":[{"output_type":"execute_result","execution_count":122,"data":{"text/plain":"count       784\nunique        1\ntop       False\nfreq        784\ndtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().any().describe()","execution_count":123,"outputs":[{"output_type":"execute_result","execution_count":123,"data":{"text/plain":"count       784\nunique        1\ntop       False\nfreq        784\ndtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train /= 255.0\ntest /= 255.0","execution_count":124,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reshape"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train.values.reshape(-1,28,28,1)\ntest=test.values.reshape(-1,28,28,1)","execution_count":125,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)","execution_count":126,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split Training and Validation Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=2)","execution_count":127,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[0][:,:,0])","execution_count":128,"outputs":[{"output_type":"execute_result","execution_count":128,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f426db0d350>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":129,"outputs":[{"output_type":"execute_result","execution_count":129,"data":{"text/plain":"(37800, 10)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## CNN"},{"metadata":{},"cell_type":"markdown","source":"### Defining the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32,(5,5),activation='relu',padding='same',input_shape=(28,28,1)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(32,(5,5),activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2),strides=(2,2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2),strides=(2,2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256,activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(10,activation='softmax')\n])\nmodel.summary()","execution_count":130,"outputs":[{"output_type":"stream","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_24 (Conv2D)           (None, 28, 28, 32)        832       \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 28, 28, 32)        128       \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 28, 28, 32)        25632     \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 28, 28, 32)        128       \n_________________________________________________________________\nmax_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 14, 14, 64)        18496     \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 14, 14, 64)        256       \n_________________________________________________________________\nconv2d_27 (Conv2D)           (None, 14, 14, 64)        36928     \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 14, 14, 64)        256       \n_________________________________________________________________\nmax_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 7, 7, 64)          0         \n_________________________________________________________________\nconv2d_28 (Conv2D)           (None, 7, 7, 64)          36928     \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 7, 7, 64)          256       \n_________________________________________________________________\nconv2d_29 (Conv2D)           (None, 7, 7, 64)          36928     \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 7, 7, 64)          256       \n_________________________________________________________________\nmax_pooling2d_14 (MaxPooling (None, 3, 3, 64)          0         \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 3, 3, 64)          0         \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 576)               0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 256)               147712    \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 256)               1024      \n_________________________________________________________________\ndropout_20 (Dropout)         (None, 256)               0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 10)                2570      \n=================================================================\nTotal params: 308,330\nTrainable params: 307,178\nNon-trainable params: 1,152\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Initializing Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer=tf.keras.optimizers.RMSprop(lr=0.001)","execution_count":131,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])","execution_count":132,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen=ImageDataGenerator(rotation_range=40,\n                          width_shift_range=0.2,\n                          height_shift_range=0.2,\n                          shear_range=0.2,\n                          zoom_range=0.2,\n                          horizontal_flip=True,\n                          fill_mode='nearest')\ndatagen.fit(X_train)","execution_count":133,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_schedule = tf.keras.callbacks.LearningRateScheduler( lambda epoch : 1e-8 * 10 ** (epoch/15))","execution_count":134,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=120),\n                              epochs = 75, validation_data = (X_val,y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // 120\n                              , callbacks=[lr_schedule])","execution_count":135,"outputs":[{"output_type":"stream","text":"Train for 315 steps, validate on 4200 samples\nEpoch 1/75\n315/315 - 13s - loss: 3.2832 - acc: 0.1055 - val_loss: 2.7112 - val_acc: 0.0971\nEpoch 2/75\n315/315 - 12s - loss: 3.2670 - acc: 0.1060 - val_loss: 2.6197 - val_acc: 0.0912\nEpoch 3/75\n315/315 - 12s - loss: 3.2699 - acc: 0.1026 - val_loss: 2.6222 - val_acc: 0.0843\nEpoch 4/75\n315/315 - 12s - loss: 3.2702 - acc: 0.1044 - val_loss: 2.6187 - val_acc: 0.0821\nEpoch 5/75\n315/315 - 12s - loss: 3.2877 - acc: 0.1014 - val_loss: 2.6182 - val_acc: 0.0810\nEpoch 6/75\n315/315 - 12s - loss: 3.2640 - acc: 0.1043 - val_loss: 2.6154 - val_acc: 0.0814\nEpoch 7/75\n315/315 - 12s - loss: 3.2738 - acc: 0.1048 - val_loss: 2.6129 - val_acc: 0.0821\nEpoch 8/75\n315/315 - 13s - loss: 3.2772 - acc: 0.1033 - val_loss: 2.6115 - val_acc: 0.0821\nEpoch 9/75\n315/315 - 12s - loss: 3.2806 - acc: 0.1042 - val_loss: 2.6086 - val_acc: 0.0833\nEpoch 10/75\n315/315 - 12s - loss: 3.2651 - acc: 0.1071 - val_loss: 2.6049 - val_acc: 0.0829\nEpoch 11/75\n315/315 - 12s - loss: 3.2663 - acc: 0.1074 - val_loss: 2.6040 - val_acc: 0.0824\nEpoch 12/75\n315/315 - 12s - loss: 3.2702 - acc: 0.1033 - val_loss: 2.5985 - val_acc: 0.0838\nEpoch 13/75\n315/315 - 12s - loss: 3.2657 - acc: 0.1052 - val_loss: 2.5945 - val_acc: 0.0829\nEpoch 14/75\n315/315 - 12s - loss: 3.2585 - acc: 0.1059 - val_loss: 2.5850 - val_acc: 0.0864\nEpoch 15/75\n315/315 - 12s - loss: 3.2535 - acc: 0.1069 - val_loss: 2.5763 - val_acc: 0.0869\nEpoch 16/75\n315/315 - 12s - loss: 3.2531 - acc: 0.1058 - val_loss: 2.5644 - val_acc: 0.0893\nEpoch 17/75\n315/315 - 12s - loss: 3.2439 - acc: 0.1079 - val_loss: 2.5465 - val_acc: 0.0919\nEpoch 18/75\n315/315 - 12s - loss: 3.2312 - acc: 0.1082 - val_loss: 2.5300 - val_acc: 0.0931\nEpoch 19/75\n315/315 - 12s - loss: 3.2121 - acc: 0.1114 - val_loss: 2.5095 - val_acc: 0.0976\nEpoch 20/75\n315/315 - 11s - loss: 3.2001 - acc: 0.1097 - val_loss: 2.4806 - val_acc: 0.1031\nEpoch 21/75\n315/315 - 12s - loss: 3.1817 - acc: 0.1132 - val_loss: 2.4454 - val_acc: 0.1105\nEpoch 22/75\n315/315 - 12s - loss: 3.1618 - acc: 0.1152 - val_loss: 2.4052 - val_acc: 0.1207\nEpoch 23/75\n315/315 - 12s - loss: 3.1200 - acc: 0.1181 - val_loss: 2.3489 - val_acc: 0.1393\nEpoch 24/75\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-135-199db5e1ce6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               , callbacks=[lr_schedule])\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nax1 = plt.subplot(1,2,1)\nax1.plot(history.history['loss'], color='b', label='Training Loss') \nax1.plot(history.history['val_loss'], color='r', label = 'Validation Loss',axes=ax1)\nlegend = ax1.legend(loc='best', shadow=True)\nax2 = plt.subplot(1,2,2)\nax2.plot(history.history['acc'], color='b', label='Training Accuracy') \nax2.plot(history.history['val_acc'], color='r', label = 'Validation Accuracy')\nlegend = ax2.legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_val)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_val, axis=1)\nimport scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_true,y_pred_classes,title='Confusion Matrix for Train Data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting results on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.predict(test)\nresults = np.argmax(results, axis=1)\nresults = pd.Series(results, name='Label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001), name='ImageId'), results], axis=1)\nsubmission.to_csv(r'Digit_Recognizer', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}